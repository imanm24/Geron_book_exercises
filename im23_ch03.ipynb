{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Machine Learning with Scikit-Learn, Keras & Tensorflow\n",
    "\n",
    "# By Aure'lien Ge'ron\n",
    "\n",
    "## Chapter 3: Classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.\n",
    "\n",
    "We suppose to use `KNeighborsClassifier` for the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This part id from Ge'ron's notebook.\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import timeit\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This part id from Ge'ron's notebook.\n",
    "#Loading data\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "#check the keys:\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get assign the data X and the labels Y. I pick up the first \"m_NG\" for the training. \n",
    "##This data is already shuffled. \n",
    "# reading X and Y \n",
    "X,Y = mnist['data'], mnist['target'] \n",
    "\n",
    "#changing labels from string to integers\n",
    "Y = Y.astype(np.uint8)\n",
    "\n",
    "#split:\n",
    "#m_Ng is the \"m\" that Andrew Ng uses for the number of data for the training. \n",
    "m_NG = 60000\n",
    "X_train, X_test, Y_train, Y_test= X[:m_NG], X[m_NG:], Y[:m_NG], Y[m_NG:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.0522802790000014 sec.\n"
     ]
    }
   ],
   "source": [
    "# scaling the data, X_train\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scalar = StandardScaler()\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "X_train_scaled = std_scalar.fit_transform(X_train)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', (stop - start),'sec.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We define a K-neghbor classifier and a parameter grid. \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kn_clf= KNeighborsClassifier()\n",
    "\n",
    "\n",
    "par_grid_search=[{'n_neighbors':[3,4,5,6,7], 'weights':['uniform','distance']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the search function\n",
    "grid_search=GridSearchCV(kn_clf,par_grid_search,cv=5,scoring='accuracy',verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END .....................n_neighbors=3, weights=uniform; total time=  18.5s\n",
      "[CV] END .....................n_neighbors=3, weights=uniform; total time=  13.7s\n",
      "[CV] END .....................n_neighbors=3, weights=uniform; total time=  12.7s\n",
      "[CV] END .....................n_neighbors=3, weights=uniform; total time=  12.8s\n",
      "[CV] END .....................n_neighbors=3, weights=uniform; total time=  13.0s\n",
      "[CV] END ....................n_neighbors=3, weights=distance; total time=  12.5s\n",
      "[CV] END ....................n_neighbors=3, weights=distance; total time=  12.4s\n",
      "[CV] END ....................n_neighbors=3, weights=distance; total time=  12.3s\n",
      "[CV] END ....................n_neighbors=3, weights=distance; total time=  12.4s\n",
      "[CV] END ....................n_neighbors=3, weights=distance; total time=  12.6s\n",
      "[CV] END .....................n_neighbors=4, weights=uniform; total time=  16.5s\n",
      "[CV] END .....................n_neighbors=4, weights=uniform; total time=  15.9s\n",
      "[CV] END .....................n_neighbors=4, weights=uniform; total time=  16.0s\n",
      "[CV] END .....................n_neighbors=4, weights=uniform; total time=  16.0s\n",
      "[CV] END .....................n_neighbors=4, weights=uniform; total time=  15.8s\n",
      "[CV] END ....................n_neighbors=4, weights=distance; total time=  16.7s\n",
      "[CV] END ....................n_neighbors=4, weights=distance; total time=  16.2s\n",
      "[CV] END ....................n_neighbors=4, weights=distance; total time=  16.4s\n",
      "[CV] END ....................n_neighbors=4, weights=distance; total time=  16.0s\n",
      "[CV] END ....................n_neighbors=4, weights=distance; total time=  15.4s\n",
      "[CV] END .....................n_neighbors=5, weights=uniform; total time=  16.1s\n",
      "[CV] END .....................n_neighbors=5, weights=uniform; total time=  15.8s\n",
      "[CV] END .....................n_neighbors=5, weights=uniform; total time=  15.9s\n",
      "[CV] END .....................n_neighbors=5, weights=uniform; total time=  15.9s\n",
      "[CV] END .....................n_neighbors=5, weights=uniform; total time=  16.9s\n",
      "[CV] END ....................n_neighbors=5, weights=distance; total time=  16.8s\n",
      "[CV] END ....................n_neighbors=5, weights=distance; total time=  16.7s\n",
      "[CV] END ....................n_neighbors=5, weights=distance; total time=  17.5s\n",
      "[CV] END ....................n_neighbors=5, weights=distance; total time=  16.4s\n",
      "[CV] END ....................n_neighbors=5, weights=distance; total time=  16.4s\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=  16.4s\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=  16.2s\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=  16.1s\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=  16.3s\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=  16.0s\n",
      "[CV] END ....................n_neighbors=6, weights=distance; total time=  16.4s\n",
      "[CV] END ....................n_neighbors=6, weights=distance; total time=  15.7s\n",
      "[CV] END ....................n_neighbors=6, weights=distance; total time=  15.9s\n",
      "[CV] END ....................n_neighbors=6, weights=distance; total time=  16.4s\n",
      "[CV] END ....................n_neighbors=6, weights=distance; total time=  16.1s\n",
      "[CV] END .....................n_neighbors=7, weights=uniform; total time=  18.0s\n",
      "[CV] END .....................n_neighbors=7, weights=uniform; total time=  16.6s\n",
      "[CV] END .....................n_neighbors=7, weights=uniform; total time=  16.3s\n",
      "[CV] END .....................n_neighbors=7, weights=uniform; total time=  16.5s\n",
      "[CV] END .....................n_neighbors=7, weights=uniform; total time=  17.3s\n",
      "[CV] END ....................n_neighbors=7, weights=distance; total time=  16.6s\n",
      "[CV] END ....................n_neighbors=7, weights=distance; total time=  17.8s\n",
      "[CV] END ....................n_neighbors=7, weights=distance; total time=  19.0s\n",
      "[CV] END ....................n_neighbors=7, weights=distance; total time=  18.0s\n",
      "[CV] END ....................n_neighbors=7, weights=distance; total time=  17.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'n_neighbors': [3, 4, 5, 6, 7],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perforing the search\n",
    "grid_search.fit(X_train_scaled,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which one was the best?\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9427833333333332 {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.9442833333333335 {'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.9408666666666667 {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.9465166666666667 {'n_neighbors': 4, 'weights': 'distance'}\n",
      "0.94205 {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.94435 {'n_neighbors': 5, 'weights': 'distance'}\n",
      "0.9405000000000001 {'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.9447166666666666 {'n_neighbors': 6, 'weights': 'distance'}\n",
      "0.9406666666666667 {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.94235 {'n_neighbors': 7, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Let's look at all the performances\n",
    "cv_res=grid_search.cv_results_\n",
    "for acc,params in zip(cv_res[\"mean_test_score\"],cv_res[\"params\"]):\n",
    "    print(acc,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9489"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance on the test set.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_test_scaled = std_scalar.transform(X_test.astype(np.float64))\n",
    "Y_test_pred = grid_search.predict(X_test_scaled)\n",
    "\n",
    "accuracy_score(Y_test, Y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    " - First I checked `'n_neighbors':[5,10,30]` and the best was 5, so I looked around 5, which is what we have above. \n",
    " - In the [notebook](https://github.com/ageron/handson-ml2) provided by Ge'ron on GitHub, there is no scaling. They use the original data.But the final conclusion is the same, namely `'n_neighbors'=4` and `'weights'='distance'` is the best. \n",
    " - They get a better performance with the original data! Here we get around `95%` on the test set and they have `97%`. It is remarkable that the performance is better without the scaling! In the book with SGDclassifier the performance increases around 5% by scaling the data! \n",
    " - Although they get a `97%` accuracy, but they have a warning for a very long running time, i.e. 16 hours! With the sacling it only took a few minutes even though I also considered two more values for `'n_neighbors'`. So this is a big difference! \n",
    " - Note that with the scaling we get around `95%` by using the `KNeighborsClassifier`. This is already `6%` better than the `SGDClassifier`. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2. \n",
    "\n",
    "We suppose to add some \"artificial data\" to the dataset by shifting each image to left, right,up and down by one pixel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifing a matrix by one column/row can be done by multiplying a shift matrix with it. `numpy` has a function for this which is `roll`. But I follow the suggestion in the book and use the `shift` from `scipy`.\n",
    "\n",
    "The `shift_op` function and the way that I construct the *augmented* data is from the notebook by Ge'ron. Apart from changes to variable names to those I have been using, I do a bit more:\n",
    "\n",
    " - I first tried to do the shift on all images, which is of course possible. But performing scaling on them made my notebook frozen. So I just pick up part of data and do the shifts on those. \n",
    "\n",
    " - In addition I added a few lines to see how long does things take. \n",
    " \n",
    " - I will do a permutation and then feed the data for the fitting-**Shuffling**. \n",
    " \n",
    " - I did a grid search like above, but the result was the same. So I just use the best paramaters here.  \n",
    " \n",
    " - As we see, like what it is written in the Ge'ron's notebook, the accuracy on the test set increases by sth like `0.6%`-from `94.9%` to `95.5%`. So it increases but less than a percent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "def shift_op(x,l_r,u_d):\n",
    "    x = x.reshape((28, 28))\n",
    "    x_shifted = shift(x, [l_r, u_d], cval=0, mode=\"constant\")\n",
    "    return x_shifted.reshape([-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  4.533125458999848 sec.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "X_aug=[]\n",
    "Y_aug=[]\n",
    "\n",
    "# number of data for augmentation. Here it is 10000 but I write it in terms of m_NG\n",
    "N_aug = m_NG//6\n",
    "\n",
    "for l_r,u_d in [[1,0],[-1,0],[0,1],[0,-1]]:\n",
    "    for image,num in zip(X_train[:N_aug],Y_train[:N_aug]):\n",
    "        X_aug.append(shift_op(image,l_r,u_d))\n",
    "        Y_aug.append(num)\n",
    "        \n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', (stop - start),'sec.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 784), (40000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change lists to numpy arrays\n",
    "X_aug = np.asarray(X_aug)\n",
    "Y_aug = np.asarray(Y_aug)\n",
    "\n",
    "#check the dimensions\n",
    "X_aug.shape,Y_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.3302451280001151 sec.\n"
     ]
    }
   ],
   "source": [
    "# merge all the data\n",
    "start = timeit.default_timer()\n",
    "X_train_with_aug=np.concatenate((X_train,X_aug),axis=0)\n",
    "Y_train_with_aug=np.concatenate((Y_train,Y_aug),axis=0)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', (stop - start),'sec.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 784), (100000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dimensions\n",
    "X_train_with_aug.shape,Y_train_with_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "X_t_w_a_scaled = std_scalar.fit_transform(X_train_with_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 784), (100000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#permute\n",
    "permute = np.random.permutation(X_t_w_a_scaled.shape[0])\n",
    "X_permuted, Y_permuted = X_t_w_a_scaled[permute], Y_train_with_aug[permute]\n",
    "X_permuted.shape, Y_permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_clf_aug= KNeighborsClassifier(**grid_search.best_params_)\n",
    "\n",
    "kn_clf_aug.fit(X_permuted,Y_permuted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9552"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = std_scalar.transform(X_test)\n",
    "Y_test_pred = kn_clf_aug.predict(X_test_scaled)\n",
    "accuracy_score(Y_test, Y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
